import pandas as pd
import numpy as np
import os
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.preprocessing import MinMaxScaler


def initProc(path1):
    df_Csv = pd.read_csv(path1)

    df_Csv = df_Csv.drop(
        columns=['SHA1', 'FirstSeenDate', 'Identify', 'PE_TYPE'])
    df_Csv = df_Csv.drop(columns=['SizeOfOptionalHeader', 'Magic'])

    df_Csv['ImportedDlls'] = df_Csv['ImportedDlls'].apply(
        lambda x: ', '.join(sorted(set(x.split(' ')))))
    df_Csv['ImportedDlls'] = df_Csv['ImportedDlls'].str.lower()
    df_Csv['ImportedSymbols'] = df_Csv['ImportedSymbols'].str.lower()
    df_Csv['ImportedSymbols'] = df_Csv['ImportedSymbols'].str.replace(
        ' ', ', ')

    for i in range(len(df_Csv)):
        if '.' not in df_Csv['ImportedDlls'][i]:
            df_Csv.drop(i, axis=0, inplace=True)

    return df_Csv


def vectorVals(df_Csv, col1):

    if col1 == "ImportedDlls":
        cvec = CountVectorizer(
            stop_words='english',
            min_df=0.001,
            max_df=0.8,
            ngram_range=(1, 1),
            token_pattern='[a-zA-Z0-9$&+:;=?@#|<>.^*()%!-]+')
        cvec.fit(df_Csv[col1])
    else:
        cvec = CountVectorizer(stop_words='english',
                               min_df=0.005,
                               max_df=0.9,
                               ngram_range=(1, 1))
        cvec.fit(df_Csv[col1])

    cvec_counts = cvec.transform(df_Csv[col1])
    occ = np.asarray(cvec_counts.sum(axis=0)).ravel().tolist()
    counts_df = pd.DataFrame({
        'term': cvec.get_feature_names(),
        'occurrences': occ
    })
    counts_df.sort_values(by='occurrences', ascending=False).head(10)

    transformer = TfidfTransformer()
    transformed_weights = transformer.fit_transform(cvec_counts)
    transformed_weights

    weights = np.asarray(transformed_weights.mean(axis=0)).ravel().tolist()
    weights_df1 = pd.DataFrame({
        'term': cvec.get_feature_names(),
        'weight': weights
    })
    weights_df1.sort_values(by='weight', ascending=False).head(10)

    return weights_df1


def newDF(df_Weights, df_User, col1):
    list1 = list(df_Weights.term)
    count1 = 0

    df_Temp = pd.DataFrame(0,
                           index=[i for i in range(1,
                                                   len(df_User) + 1)],
                           columns=list1)

    for i in df_User[col1]:
        count1 += 1
        temp1 = i.split()

        for j in temp1:
            for col in df_Temp.columns:
                if j[:-1] == col:
                    df_Temp[col][count1] = 1

    return df_Temp


def runme():
    path1 = "/home/beastmode/Desktop/DJSCE/Hackathons/SPIT/brazilian-malware.csv"

    df_Csv = initProc(path1)
    weights_df1 = vectorVals(df_Csv, 'ImportedDlls')
    weights_df2 = vectorVals(df_Csv, 'ImportedSymbols')

    input_Fname = "temp.csv"
    f_Path = "/home/beastmode/Desktop/DJSCE/Hackathons/SPIT/CSV/temp.csv"

    df_User = initProc(f_Path)

    df_Temp1 = newDF(weights_df1, df_User, 'ImportedDlls')
    df_Temp2 = newDF(weights_df2, df_User, 'ImportedSymbols')
    print(df_Temp1.shape)
    print(df_Temp2.shape)
    print(df_User.shape)
    frame_List = [df_User, df_Temp1]
    final_Csv = pd.concat(
        frame_List,
        axis=1,
        verify_integrity=True,
    )
    frame_list = [final_Csv, df_Temp2]
    final_Csv = pd.concat(
        frame_List,
        axis=1,
        verify_integrity=True,
    )

    # for row in final_Csv.iterrows():
    #     count2 += 1
    #     tuple1 = row

    #     if count2 == 1:
    #         tuple2 = tuple1

    # # print(tuple1, tuple2)
    # row1 = final_Csv.iloc[0]
    # row2 = final_Csv.iloc[1]
    # row3 = []
    # for i in range(len(row1)):
    #     row3.append(handle(row1[i]) or handle(row2[i])))

    # print(row3)
    f_Path2 = "/home/beastmode/Desktop/DJSCE/Hackathons/SPIT/CSV/temp1.csv"
    print(final_Csv.shape)

    final_Csv.to_csv(f_Path2)
